% Video captioning models have become increasingly important in today's digital age. As video content continues to proliferate across various platforms, the need for accessible and engaging captions has never been more critical. These models provide a way for people with hearing disabilities or those who prefer to consume content with captions to access video content. \cite{intro1} Additionally, they can be used to translate captions into multiple languages, improving the reach of video content across the globe. \cite{intro2} Furthermore, video captioning models can enhance the user experience of video content by providing text that can be followed along with the audio. In this paper, we will explore the various reasons why video captioning models are crucial and how they have impacted the world of digital content.

% The aim of this research project is to improve the efficiency of video consumption by presenting the most salient and relevant information in a concise and understandable format. The motivation for this study comes from the automatic chapter generation feature in YouTube, which allows users to navigate long videos more easily and locate important segments. Specifically, we will investigate how to automatically identify and summarize the key parts of a video, such as the main topics, concepts, and events, using natural language processing and machine learning techniques. By doing so, we hope to reduce the time and effort required for users to comprehend large or lengthy videos, especially in educational contexts where video lectures or tutorials can last for hours.

% The purpose of video description generation, also known as video captioning, is to automatically generate captions for videos by understanding the action and events in the video, which can help in the retrieval of the video efficiently through text \cite{intro4}. Video captioning is a challenging task due to the complexity and diversity of video content, and it requires understanding the temporal relationship between video frames \cite{intro3}. The automatic generation of video descriptions can be useful in many aspects, including helping visually impaired individuals to understand the content of videos. With the incomparable performance of deep learning in the field of computer vision and natural language processing, research in this field has been exponentially increasing throughout the past decades \cite{intro2}. Therefore, developing accurate video captioning models is crucial for various applications such as video indexing and retrieval.

Video captioning models \cite{Aafaq2019SpatioTemporalDA,Chen2019DeepLF, Liu2018SibNetSC,Pei2019MemoryAttendedRN,Shi2020LearningSC} play a critical role in providing captions for video content that are both accessible and engaging. This is particularly important for individuals with hearing impairments or those who prefer closed captions \cite{intro1}. The automatic generation of video descriptions can also help visually impaired individuals to understand the content of videos \cite{intro4}. By translating captions into multiple languages, these models can also help increase the reach of video content around the world \cite{intro2}. Moreover, video captioning models can enhance a user's viewing experience by providing text that can be followed along with the audio. However, video captioning continues to remain a challenging task as it requires understanding the temporal relationship between video frames \cite{intro2}. Developing accurate video captioning models is thus crucial for various other applications such as video indexing and retrieval.

Our research focuses on leveraging natural language processing and deep learning methods to automatically identify and summarise significant elements of a video, such as its primary topics, concepts, and events. This can help reduce the time and effort required for users to comprehend large or lengthy videos, especially in educational contexts where video lectures or tutorials can last for hours. For example, the automatic chapter generation feature in YouTube allows users to navigate long videos more easily and locate important segments. In contrast to generating video summaries or highlights, our objective is to generate video descriptions that concisely capture the essence of the content, thereby enhancing accessibility and comprehension for a broader audience.